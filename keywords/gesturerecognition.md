Human-Machine social [interaction](../main/glossary/.md#computer-human_interaction) usually relies on verbal or written communication, this is not the case for gesture recognition. Gesture Recognition is an area of computation science which detects and interprets human body movement. Much of this is done using [machine learning](../main/glossary/.md#machinelearning) algorithims[^kobylarz01wiki]. 

Early gesture recognition systems include the Sketchpad System, created by Ivan sutherland. This system was the first graphical interface to detect human gesture. This was follwoed by the Mouse, the first device which tracked movement across an x-y axis[englebart02wiki]. 

Currently gesture recognition technologies are employed across many devices and softwares like phones. The most recent technological developments include facial recognition technology [../main/glossary/.md#facialRecognition].  The employment of gesture recognition in new media like interactive art and Virtual Reality (VR) adds a layer of deep [immersion](../main/glossary/.md#immersion). 


[^kobylarz01wiki]:Kobylarz, Jhonatan; Bird, Jordan J.; Faria, Diego R.; Ribeiro, Eduardo Parente; Ekárt, Anikó 2020. Thumbs up, thumbs down: non-verbal human-robot interaction through real-time EMG classification via inductive and supervised transductive transfer learning. Journal of Ambient Intelligence and Humanized Computing. 11 (12). Springer Science and Business Media LLC: 6021–6031. doi:10.1007/s12652-020-01852-z. ISSN 1868-5137.
[englebart02wiki]:Engelbart, Douglas and William English 1968,. AFIPS Conference Proceedings ,  395–410. 
[sutherland03wiki]:Sutherland, Ivan E. 1963. "Sketchpad: A Man-Machine Graphical Communication System." Technical Report. MIT Lincoln Laboratory, Lexington, MA, USA.
